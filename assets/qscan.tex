\section{Zrównoleglenie DBSCAN}

\subsection{Wydajność DBSCAN a podział danych}
Idea zrównoleglenia DBSCAN pojawiła się podczas analizy możliwości optymalizacji dostępu do otoczenia punktu. Skupiłem się głównie na metodzie projekcji, ponieważ dzięki swojej prostocie ułatwia rozważania. Metoda nierówności trójkąta działa bardzo podobnie do metody projekcji, dlatego większość uwag stosuje się równie dobrze do metody nierówności trójkąta.\par
Załóżmy, że jest poszukiwane otoczenie punktu $ p $. Działanie metody projekcji można interpretować następująco. Metoda projekcji pozwala ograniczyć zbiór przeszukiwanych danych do punktów znajdujących się w wycinku przestrzeni(niebieskie pole na \myhyperref{qscan:projection-space-cut}{rysunku}) ograniczonym do $ <p_n-\varepsilon\,;\,p_n+\varepsilon> $ wzdłuż wybranego wymiaru $ n $, gdzie $ p_n $ to projekcja punktu $ p $ na wymiar $ n $. W ten sposób wyznaczenie otoczenia punktu $ p $ wymaga tylko wyznaczenia odległości do punktu $ p $ od punktów, których projekcja na $ n $-ty wymiar mieści się w przedziale $ <p_n-\varepsilon\,;\,p_n+\varepsilon> $. \myhyperref{qscan:projection-space-cut}{Rysunek} przedstawia użycie metody projekcji. Przeszukiwane są tylko punkty znajdujące się na niebieskim polu, podczas gdy otoczenie punktu $ p $ znajduje się w czerwonym okręgu.\par
\input{assets/figures/projection-space-cut}
Na podstawie powyższego rozważania można dojść do wniosku, że wydajność wyznaczania otoczenia za pomocą metody projekcji zależy proporcjonalnie od liczby punktów w przeszukiwanym wycinku przestrzeni. Zmniejszenie liczby punktów w przeszukiwanym obszarze powinno zwiększyć wydajność poszukiwania otoczenia, a w konsekwencji wydajność grupowania. Najprostszym sposobem na pozbycie się części punktów jest podział zbioru danych na mniejsze części i wykonanie grupowania na każdym podzbiorze oddzielnie. Istotą tej optymalizacji jest fakt, że liczba poszukiwań otoczenia zawsze będzie równa sumarycznej liczbie punktów, niezależnie od podziału danych, ale liczba punktów przeszukiwanych do znalezienia otoczenia będzie mniejsza.\par
\input{assets/figures/projection-space-bad-good-cut}
Na \myhyperref{qscan:projection-space-bad-good-cut}{rysunku} są pokazane dwa przykładowe podziały danych. Na \ref{qscan:projection-space-bad-good-cut-bad} dane zostały podzielone tak, że nie uzyskano żadnej redukcji liczby punktów w przeszukiwanych wycinkach przestrzeni. Podział danych wzdłuż wymiaru, z którego korzysta metoda projekcji nie ma sensu. Najlepiej jest dokonać podziału wzdłuż innego wymiaru tak jak na \ref{qscan:projection-space-bad-good-cut-good}, gdzie uzyskano redukcję liczby punktów o połowę.\par
\input{assets/tables/projection-space-cut-times}
W \myhyperref{qscan:projection-space-cut-times}{tabeli} zawarte są czasy grupowania rzeczywistych danych z podziałem zbioru danych oraz bez. Punkty zostały podzielone na podstawie mediany tak, żeby podzielić dane na dwie równe części. Wyniki w dużym stopniu zależą od charakterystyki danych, ale we wszystkich czterech przypadkach grupowanie na częściach odbyło się szybciej niż grupowanie całego zbioru danych. W przypadkach $ birch $ oraz $ covtype $ osiągnięto niemal dwukrotne przyśpieszenie.\par
Jak się okazało istnieje potencjał w zastosowaniu zasady ,,dziel i rządź'' w przypadku DBSCAN. Dzielenie zbioru danych na części przynosi wymierne efekty. Co więcej, grupowanie za pomocą tej metody nie tylko może być wydajniejsze, ale dzieląc dane na części i grupując je niezależnie, otrzymujemy możliwość zrównoleglenia algorytmu. Rozwiązanie w obecnej formie nie nadaje się jednak do użytku, ponieważ mogą istnieć grupy, które znajdują się jednocześnie po obydwu stronach granicy podziału i po rozdzieleniu ich części mogą zostać potraktowane jak różne grupy. Co więcej, podział może spowodować, że  część punktów, które zostałyby zakwalifikowane do grupy, nie znajdzie się w niej, a niektóre grupy w ogóle nie zostaną utworzone. Aby rozwiązanie dawało pożądane wyniki, potrzebna jest metoda scalania pogrupowanych podzbiorów danych.

\subsection{Scalanie pogrupowanych podzbiorów zbioru danych}
Przez \textit{typ} punktu będzie rozumiana klasyfikacja punktu jako punkt rdzeniowy, brzegowy albo szum. Projekcja punktu $ v $ na wymiar $ d $ będzie oznaczana $ v_d $. \textit{Granicą podziału} będę nazywał hiperpłaszczyznę o równaniu $ d=b $, gdzie $ d $ jest pewnym ustalonym wymiarem nazywanym \textit{wymiarem granicy podziału} oraz $ b $ jest pewną ustaloną wartością nazywaną \textit{pozycją granicy podziału}.

Dla uproszczenia przyjmę, że istnieje granica podziału o wymiarze $ d $ i pozycji $ b $, która dzieli punkty ze zbioru danych $ D $ na dwa podzbiory $ L $ oraz $ R $. Punkty $ v $ takie, że $ v_d $ jest mniejsze lub równe od $ b $, zostają włączone do podzbioru $ L $, a punkty $ v_d \ge b $ trafiają do $ R $.

\input{assets/figures/qscan-partitioned-clusters}

Grupowanie zbiorów $ L $ oraz $ R $ daje wyniki takie, że dla każdego punktu, który spełnia warunek $ v_d \le b - \varepsilon $ dla $ L $ oraz $ v_d \ge b + \varepsilon $ dla $ R $, jeśli ten punkt jest punktem typu $ t $ w zbiorze $ L $ lub $ R $, to jest też odpowiednio punktem typu $ t $ w zbiorze $ D $, a dla punktów spełniających $ \abs{v_d - b} < \varepsilon  $ ta zależność nie zachodzi (\myhyperref{qscan:partitioned-clusters}{rysunek}). Otoczenie wyznaczane dla punktów, które są w odległości większej niż lub równej $ \varepsilon $ od granicy podziału jest takie samo w zbiorze $ D $, co w podzbiorach $ L $ i $ R $, stąd dla tych punktów zachodzi, że typ punktu w $ L $ lub $ R $ jest taki sam jak w $ D $. Dodatkowo, o wyniku grupowania można powiedzieć, że jeśli punkty rdzeniowe $ v $ i $ w $, spełniające  warunek $ v_d, w_d \le b - \varepsilon $ dla $ L $ oraz $ v_d, w_d \ge b + \varepsilon $ dla $ R $, znajdują się w różnych grupach w zbiorze $ D $, to w podzbiorach $ L $ oraz $ R $ też znajdują się w różnych grupach, w drugą stronę ta zależność nie zachodzi.\par
Fakt, że wyniki grupowania podzbiorów $ L $ oraz $ R $ różnią się od wyników grupowania zbioru D dla punktów spełniających warunek $ \abs{v_d-b} < \varepsilon $ powoduje, że może nie być możliwe odtworzenie na podstawie grupowania $ L $ oraz $ R $ grupowania zbioru $ D $. Z tym problemem można spróbować sobie poradzić, rozszerzając zakres punktów włączanych do podzbiorów $ L $ oraz $ R $ o $ \varepsilon $. Teraz punkty znajdujące się w $ L $ będą spełniać warunek $ v_d \le b + \varepsilon $, a punkty w $ R $ warunek $ v_d \ge b - \varepsilon $. Dzięki rozszerzeniu podzbiorów $ L $ oraz $ R $ otrzymujemy grupowanie, które pozwala odzwierciedlić typy punktów dla całego zbioru danych $ D $. Wyniki grupowania $ L $ dla punktów $ v_d \le b $ oraz $ R $ dla $ v_d \ge b $ dają informację, które punkty wchodzą w skład grup w zbiorze $ D $, ale nie zachowują odpowiednich identyfikatorów grup.\par
Grupy znajdujące się zarówno w $ L $ i $ R $ będą posiadać różne etykiety \mbox{w każdym} z tych zbiorów (\myhyperref{qscan:partitioned-clusters-L-R}{rysunek}). Niektóre grupy mogą przez podział na $ L $ i $ R $ zostać rozbite na fragmenty, z których każdy będzie miał inną etykietę grupy (\myhyperref{qscan:partitioned-clusters-L-R}{rysunek}), stąd na pojedynczą grupę w zbiorze $ D $ może składać się kilka grup wynikających z grupowań podzbiorów $ L $ oraz $ R $. Rozwiązaniem tych problemów jest odpowiednie odwzorowanie grup z podzbiorów $ L $ oraz $ R $, na grupy spójne z wynikami grupowania $ D $. Do określenia odwzorowania grup $ L $, $ R $ na grupy $ D $ można wykorzystać część wspólną zbiorów $ L $ oraz $ R $. Część wspólna obejmuje punkty $ \abs{v_d - b} \le \varepsilon $. Punkty $ v_d > b $ dla $ L $ oraz $ v_d < b $ dla $ R $ nie gwarantuję, że typ punktu wyznaczony na podstawie odpowiednio podzbiorów $ L $ i $ R $ będzie zgodny z typem tego samego punktu wyznaczonym na podstawie $ D $, stąd nie są odpowiednie do przeprowadzenia odwzorowania grup. Podzbiory $ L $ i $ R $ należy dalej rozszerzyć tak, żeby posiadały część wspólną, gdzie typy punktów wyznaczone na podstawie podzbiorów $ L $ i $ R $ są zgodne wyznaczonymi na podstawie $ D $.

Pojawia się pytanie, jak duża musi być część wspólna podzbiorów \mbox{$ L $ i $ R $}, żeby była wystarczająca do przeprowadzenia odwzorowania. Wystarczająca część wspólna podzbioru $ L $ i $ R $ to taka, która pozwoli powiązać grupę znajdującą się w $ L $ z grupą w $ R $. Aby powiązanie grup było możliwe w części wspólnej, musi znaleźć się chociaż jeden punkt, który pozwoli powiązać etykietę grupy w $ L $ z etykietą w $ R $. Dwa punkty są w tej samej grupie, jeśli są ze sobą gęstościowo połączone \cite{dbscan}. Gęstościowe połączenie między punktami może istnieć tylko, jeśli te punkty istnieją w ciągu punktów bezpośrednio gęstościowo połączonych. Największa odległość, jaka może istnieć między dwoma punktami w takim ciągu punktów bezpośrednio gęstościowo połaczonych, wynosi $ \varepsilon $. Na tej podstawie można stwierdzić, że wystarczająca jest szerokość $ \varepsilon $ części wspólnej zbiorów $ L $ i $ R $ o spójnych typach punktów z $ D $.\par

W skład rozszerzonych podzbiorów $ L $ i $ R $ wejdą teraz punkty spełniające warunki $ v_d \le b + \frac{3}{2}\varepsilon $ dla $ L $ oraz $ v_d \ge b - \frac{3}{2}\varepsilon $ dla $ R $. Punkty $ v_d \le b + \frac{1}{2}\varepsilon $ w $ L $ posiadają typy spójne z $ D $, analogicznie $ v_d \ge b - \frac{1}{2} $ w $ R $. Punkty $ v_d > b - \frac{1}{2}\varepsilon $ w $ L $ i $ v_d < b + \frac{1}{2} $ w $ R $ nie spełniają warunku spójności typów z $ D $. Takie punkty będę określał lewym obszarem brzegowym $ LE $ oraz prawym obszarem brzegowym $ RE $. Część wspólna podzbiorów $ LC $ oraz $ RC $ nazywa się rdzeniowym obszarem scalania $ MC $, a część wspólna $ L $ i $ R $ obszarem scalania $ M $. $ \myhyperref{qscan:qscan}{Rysunek} $ obrazuje zdefiniowane obszary.\par
\input{assets/figures/qscan}
Mapowanie grup można wykonać, porównując etykiety grup wyników grupowania $ L $ oraz $ R $ dla tego samego punktu. Etykiety grup, które dotyczą tego samego punktu w $ L $ i $ R $ określają tę samą grupę w zbiorze $ D $, a na grupę w zbiorze $ D $ może składać się wiele grup w zbiorach $ L $ i $ R $ tworzących relacje wiele do wielu (\myhyperref{qscan:cid-graph-groups}{rysunek}). Powiązania między etykietami grup można przedstawić jako graf (\myhyperref{qscan:cid-graph-graph}{rysunek}), gdzie węzłami są etykiety grup i etykiety połączone są krawędzią, jeśli dotyczą tej samej grupy w $ D $. Tak stworzony graf będzie dwudzielny, ponieważ powiązania etykiet tworzone są tylko pomiędzy podzbiorami $ L $ oraz $ R $, a nie w obrębie jednego podzbioru. Graf będzie zawierał tyle spójnych składowych, ile jest grup w zbiorze $ D $, ponieważ powiązania są tworzone tylko między etykietami dotyczącymi tej samej grupy w $ D $, więc każda spójna składowa grafu będzie dotyczyła jednej grupy \mbox{w $ D $}. Uspójnienie grup pochodzących z wyników grupowania $ L $ i $ R $ do grup w $ D $ sprowadza się zatem do znalezienia wszystkich spójnych składowych grafu zależności między etykietami. Wszystkie spójne składowe grafu można znaleźć za pomocą odpowiednio zmodyfikowanego przeszukiwania wszerz \cite{connectedcomponentsbfs}. Następnie należy przypisać każdej spójnej składowej unikatową etykietę grupy. Odpowiednie odwzorowanie wszystkich etykiet grup zawartych w danym komponencie do etykiety przypisanej komponentowi daje nam grupy spójne z wynikami grupowania $ D $.\par
\input{assets/figures/cid-graph}

Pojawia się pytanie, na jakim podzbiorze danych należy tworzyć graf zależności między grupami. Grupy, które nie posiadają punktów w obszarze $ M $, nie są pofragmentowane i znajdują się całkowicie w podzbiorze $ LC $ dla grup w $ L $ albo $ RC $ dla grup w $ R $, są zatem spójne z wynikami grupowania $ D $, więc nie ma sensu dla nich tworzyć odwzorowania, mogą być bezpośrednio przepisane jako grupy zbioru $ D $. Mapowanie powinno być zatem tworzone co najwyżej na podzbiorze $ M $. Grupy, które znajdują się w $ M $, występują z różnymi etykietami w $ L $ oraz $ R $ i do tego mogą być pofragmentowane. O ile grupa nie jest pofragmentowana i nie zawiera się w $ LE $ dla $ L $ oraz $ RE $ dla $ R $ to również może być przepisana jako grupa w $ D $. Może się zatem wydawać, że wystarczy stworzyć graf zależności na zbiorze $ MC $, ponieważ jak zostało wcześniej ustalone, jest wystarczający do stworzenia zależności między fragmentami grup.\par
Procedura scalania wyników grupowania $ L $ i $ R $ może więc wyglądać następująco. Na początku należy pogrupować zbiory $ L $ oraz $ R $. Następnie stworzyć odwzorowanie etykiet grup i podmienić etykiety w zbiorach $ L $ oraz $ R $ na odpowiednie odwzorowanie. W ten sposób możemy otrzymać grupowanie w zbiorze $ D $, przepisując uspójnione wyniki grupowania $ L $ na zbiór $ LC \setminus RC $ oraz uspójnione wyniki grupowania $ R $ na zbiór $ RC $.\par

Powstała procedura scalania grup ma jednak dwa problemy, które ujawniają się w przypadkach szczególnych. Pierwszy z problemów spowodowany jest niedeterministycznym charakterem punktów brzegowych. Punkty brzegowe mogą zostać zaliczone do różnych grup w zależności od algorytmu grupowania i kolejności danych. Powoduje to, że punkt brzegowy może zostać włączony w zbiorze $ L $ do grupy odpowiadającej innej grupie w zbiorze $ D $ niż grupa, do której został zaliczony w $ R $. Taki punkt może utworzyć niepoprawne wiązanie w grafie zależności etykiet, powodując, że powstanie grupa, która będzie się składała z wielu grup zbioru $ D $ (\myhyperref{qscan:qscan-problems-1}{rysunek}). Można sobie poradzić z tym problemem, ignorując punkty brzegowe podczas tworzenia grafu zależności. Pierwszy problem zostaje w ten sposób rozwiązany, ale ignorowanie punktów brzegowych tworzy kolejny problem. Jeśli w obszarze $ MC $ znajdują się punkty brzegowe pewnej grupy, ale wszystkie punkty rdzeniowe tej grupy znajdują się w $ RE $, to etykieta tej grupy nie zostanie odwzorowana na uspójnioną etykietę (\myhyperref{qscan:qscan-problems-2}{rysunek}). W ten sposób do wyniku zostanie przepisana część grupy znajdująca się w $ RE $ z etykietą grupowania $ L $ oraz punkty brzegowe znajdujące się w $ MC $ z etykietą z grupowania $ R $, tym samym niepoprawnie tworząc w ostatecznym wyniku dwie różny grupy. Ten problem udaje się rozwiązać, tworząc odwzorowanie na podstawie $ M $, \mbox{a nie} $ MC $ jak sugerowałem wcześniej.\par
\input{assets/figures/qscan-problems}
\input{assets/algorithms/merge}
Kompletną procedurę scalania częściowych wyników grupowania przedstawia \myhyperref{alg:merge}{algorytm}.

\subsection{Zrównoleglony DBSCAN}
Na podstawie algorytmu scalania częściowych wyników grupowania można skonstruować algorytm grupowania, który dzięki podziałowi danych na mniejsze części pozwoli poprawić wydajność wyszukiwania otoczenia. Proponowaną implementację przedstawia \myhyperref{alg:qscan}{algorytm}. Algorytm opiera się na rekurencyjnym podziale zbioru danych o określoną parametrem $ \delta $ głębokość podziału. Po podzieleniu powstaje $ 2^\delta $ fragmentów zbioru danych, które są następnie grupowane za pomocą metody projekcji, a potem parami scalane. Scalanie jest powtarzane aż do uzyskania grupowania zbioru $ D $.\par
\input{assets/algorithms/qscan}
Istotnym problemem jest dobór granicy podziału. Przy wyborze granicy podziału można się kierować złożonością grupowania. Przy założeniu, że ta złożoność zależy od liczby punktów jak $ n^2 $, to można przyjąć, że złożoność grupowania części $ L $ i $ R $ jest równa \myhyperref{qscan:complexity}{wyrażeniu}.
\begin{equation} \label{qscan:complexity}
	n_L^2 + n_R^2
\end{equation}
Jeśli dla uproszczenia pominie się część wspólną zbiorów $ L $ i $ R $, to złożoność można określić \myhyperref{qscan:complexity-fixed}{równaniem}.
\begin{equation} \label{qscan:complexity-fixed}
	n_L^2 + n_R^2 = n_L^2 + (n-n_L)^2 = 2n_L^2 + n^2 - 2nn_L
\end{equation}
Minimum $ \myhyperref{qscan:complexity}{wyrażenia} $ znajduje się w $ n_L = \frac{n}{2} $ (\myhyperref{qscan:complexity:label}{równanie}).
\begin{equation} \label{qscan:complexity:label}
	\frac{d}{dn_L}(2n_L^2 + n^2 - 2nn_L) = 4n_L - 2n = 0 \iff n_L = \frac{n}{2}
\end{equation}
Dobrym wyborem granicy podziału zbiorów powinna być zatem mediana projekcji zbioru $ D $ na wymiar $ d $. \myhyperref{alg:qscan}{Algorytm} stosuje właśnie medianę jako granicę podziału.\par
Kryterium doboru wymiaru podziału $ d $ może być ograniczenie negatywnego wpływu części zbiorów $ L $ i $ R $, które wykraczają za granicę $ b $, czyli $ v_d > b $ dla $ L $ i $ v_d < b $ dla $ R $. Sprowadza się to do znalezienia wymiaru, w którym jak najmniej punktów będzie znajdowało się w obszarze $ M $, tak żeby minimalizować wartości $ |L| $ i $ |R| $, a w konsekwencji wartość \myhyperref{qscan:complexity}{wyrażenia}. Do znalezienia takiego wymiaru można na przykład zastosować heurystykę polegającą na wybieraniu wymiaru o największej wartości wariancji lub średniego odchylenia bezwzględnego. Duża wartość wariancji lub odchylenia bezwzględnego świadczy zwykle o małej gęstości danych, stąd można oczekiwać, że do obszaru $ M $ o stałej szerokości $ 3\varepsilon $ trafi mało punktów. \myhyperref{alg:qscan}{Algorytm} wykorzystuje podejście z maksymalizacją średniego bezwzględnego odchylenia. Do podziału wybierany jest wymiar o maksymalnej wartości średniego bezwzględnego odchylenia.\par

\input{assets/figures/qscan-time-by-eps-delta}
Wydajność \myhyperref{alg:qscan}{algorytmu} w dużym stopniu zależy od wyboru\linebreak \mbox{parametru $ \delta $}. Algorytm dzieli dane, tworząc drzewo binarne o wysokości $ \delta + 1 $, gdzie na najniższym poziomie drzewa znajduje się $ 2^\delta $ fragmentów danych, które są potem scalane. Każdy węzeł tego drzewa nie będący na najniższym poziomie odpowiada jednemu podziałowi danych, zatem dokonywane jest $ 2^\delta - 1 $ podziałów. Przy każdym podziale danych tworzona jest na potrzeby scalania część wspólna o stałej szerokości $ 3\varepsilon $. Zakładając, że punkty w zbiorze danych rozłożone są jednorodnie z gęstością $ 1 $ w każdym z wymiarów, daje to $ 3\varepsilon(2^\delta - 1) $ punktów, dla których grupowanie jest nadmiarowo powtarzane na potrzeby scalania. Co więcej, wraz z podziałem maleje odległość pomiędzy skrajnymi wartościami punktów w zbiorze, a szerokość obszaru wspólnego $ M $ pozostaje stała, w skrajnym przypadku obszar wspólny $ M $ podzbiorów $ L $ i $ R $ może być równy $ D $. Można się zatem spodziewać, że \myhyperref{alg:qscan}{algorytm} nie będzie działał wydajnie dla bardzo dużej wartości $ \delta $ i dużych wartości $ \varepsilon $. Co więcej, dla wystarczająco dużej wartości parametru $ \varepsilon $, dla której $ M $ równa się $ D $, nie ma też sensu zrównoleglanie obliczeń. \myhyperref{fig:qscan-time-by-eps-delta}{Rysunek} przedstawia wyniki testów \myhyperref{alg:qscan}{algorytmu} dla różnych wartości $ \delta $ i $ \varepsilon $. Testy zostały przeprowadzone na niezrównoleglonej implementacji Algorytmu, tak żeby możliwe było określenie wzrostu wydajności w stosunku do metody projekcji bez podziału danych. Na wykresach widać, że \myhyperref{alg:qscan}{algorytm} działa niewydajnie dla dużych wartościach $ \delta $, a wraz ze wzrostem $ \varepsilon $ minimum czasu wykonania przesuwa się w stronę mniejszych wartości $ \delta $, co świadczy o utracie skuteczności dzielenia danych. \par
\myhyperref{table:projection-vs-qscan}{Tabela} przedstawia porównanie czasów grupowania metodą projekcji oraz \myhyperref{alg:qscan}{algorytmem}. Testy zostały przeprowadzone na różnych zbiorach danych. To, czy podział danych jest korzystny wydajnościowo, zależy od charakterystyki grupowanych danych. Zgodnie z wykresami na \myhyperref{fig:qscan-time-by-eps-delta}{rysunku} optymalna wartość $ \delta $ maleje ze wzrostem $ \varepsilon $.
\begin{table}[H]
	\centering
	\begin{tabular}{| c | c | c | c | c | c | c | c |}
		\hline
		zbiór     & $ |D| $ & $ \varepsilon $ & $ \nu_p $ & $ \nu_q $ & $ \delta $ & $ T_p [s]$ & $ T_q [s]$ \\ \hline
		covtype   & 100000  & 160 & 6 & 6 & 2 & 14.86 & 11.33  \\ \hline
		covtype   & 100000  & 120 & 6 & 6 & 5 & 9.58  & 7.56   \\ \hline
		covtype   & 100000  &  80 & 6 & 6 & 6 & 8.82  & 3.74   \\ \hline
		cup98     &  50000  &  60 & 5 & 3 & 1 & 11.37 & 13.15  \\ \hline
		cup98     &  50000  &  50 & 5 & 4 & 3 & 8.54  & 9.43    \\ \hline
		cup98     &  50000  &  40 & 5 & 4 & 4 & 6.34  & 8.23    \\ \hline
	\end{tabular}
	\caption{Czasy grupowania w zależności od zbioru danych oraz wartości $ \varepsilon $. Ze zbiorów danych została wylosowana próba rozmiaru $ |D| $. Parametry zostały dobrane tak, żeby zapewnić jak najlepszą wydajność grupowania. $ T_p $ - czas grupowania metodą projekcji z wykorzystaniem $ \nu_p $ wymiarów, $ T_q $ - czas grupowania \myhyperref{alg:qscan}{algorytmem} z parametrami $ \nu_q $, $ \delta $.}\label{table:projection-vs-qscan}
\end{table}
Przedstawiony algorytm pozwala na wydajne grupowanie danych, dla niektórych zbiorów danych wydajniejsze niż sama metoda projekcji. Największą zaletą tego algorytmu nie jest jednak wydajność, ale możliwość podziału grupowanego zbioru na mniejsze podzbiory i wykonania grupowania równolegle w oddzielnych wątkach, procesach.
